---
title: "Data Science Ethics"
description: |
  Analysis of Anonymity of Data
author: Max Feng
date: April 16, 2025
format: html
---

Privacy is widely recognized as a stringent right of human beings. In data science, data anonymization helps ensure individuals' privacy by removing personal information of the respondants. However, as computational techniques become more advanced, supposedly anonymized data can be re-identified, which leads to some serious ethical concerns.

In this project, I will analyze this ethical concern by scrutinizing two news articles that highlight the problem of poorly anonymized data and responding to four important questions. The first article by Dan Goodin introduces a data set of New York City taxi trip records that revealed the detailed comings and goins of individual taxi drivers over more than 173 million trips. In order to preserve taxi drivers' privacy, their hack license numbers and medallion numbers were obscured using the MD5 algorithm. This algorithm converts a medallion number or hack number to a longer string with letters and numbers. For example, medallion number 9Y99 or hack number 5296319 were converted to 71b9c3f3ee5efb81ca05e9b90c91c88f and 98c2b1aeb8d40ff826c6f1580a600853. Because they're one-way hashes, they can't be mathematically converted back into their original values. However, this model has proven to be flawed since a software developer successfully de-anonymized all the data. In the second article by Natasha Singer, the author incorporates many cases with poorly anonymized data and thereby claims that the old model of anonymization is no longer effective in the metadata era. One case that is brought to most attention is an analysis of credit card transactions by 1.1 million people in 10000 stores over a three-month period. Personal details were removed from the data set, but the columns contained in the data set are enough to re-identify 90 percent of the shoppers.

The first question to respond to is: Were the data made publicly available? In the first article regarding NYC taxi trip records, the data were made publicly available. Indeed, the data were released in response to a public records request. However, though more information regarding drivers' movements was revealed to public, taxi drivers' personal information was also leaked by decoding the encryption and therefore, their privacy rights were infringed. In the second article, the data of credit card transactions were also made publicly available, which is exactly the reason why the ethical concern of revealing personal identity was raised.

The second item to respond to is: Is the data identifiable? All of it? Some of it? In what way? Are the data sufficiently anonymized or old to be free of ethical concerns? Is anonymity guaranteed? In the first article regarding NYC taxi trip records, all of the data became identifiable after running all possible iterations of the patterns structured by the MD5 algorithm. According to the article, the data were not sufficiently anonymized since NYC officials could do the following two things to improve the anonymity: assigning a random number to each hack license number and medallion number and creating a secret AES key to encrypt each value individually. In the second article, 90% of the data became identifiable after combining the disclosed items in the data set (the date of each transaction, amount charged and name of the store) with publicly available information (Instagram or Twitter posts). In this case, the researchers tried their best to make their data anonymized. However, with a huge amount of addition data, it is still possible to deduce personal information.

The third item to consider is the eleventh of Data Values and Principles Manifesto, which states that "as data teams, we aim to protect the privacy and security of individuals represented in our data". This item is closely related to the ethical concern of privacy infringement. In both cases, the data teams did not successfully protect the privacy of the individuals. In the first article, taxi drivers' personal information as well as their movements were revealed by cracking the encryption. In the second article, credit card users' personal identity and each of their transactions were revealed by the released data and additional public data on the Internet.

The fourth item to ruminate is the first item of Data Values and Principles Manifesto, contending that "as data teams, we aim to use data to improve life for our users, customers, organizations, and communities". I think that both data sets help improve life for the communities. In the first case of NYC taxi trip records, the NYC officials could have a better sense of the areas that had the most taxis driving by, which implies that those areas may need more taxis around so that people can find an available taxi faster and life gets more convenient. In the second case of credit card transactions, the data set is worth studying as it outlines the living patterns and habits of individuals. Scientists will be able to infer the individuals' decision-making processes and conclude brilliant findings in psychology and sociology.

The two chosen articles provide different perspectives to analyze the ethical concern of privacy. The first article presents a case where the anonymization process is flawed and can be improved. The second article provides bad news to the entire anonymization process: any de-identification methods can be cracked and there is always the threat to disclose personal information. Does this mean we should stop producing public data? I don't this is the case either as the two articles have proven that the datasets can make life easier and better. Therefore, in face of the awkward situation, another ethical dilemma between data disclosure and privacy is put forward: if data are destined to infringe privacy, how many datasets and how much information should we disclose publicly to make a balance between data and privacy?

**References**

Goodin, D. (2014). *Poorly anonymized logs reveal NYC cab drivers’ detailed whereabouts*. Ars Technica.

Singer, N. (2015). *With a few bits of data, researchers identify “anonymous” people*. The New York Times.
